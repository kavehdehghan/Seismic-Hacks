{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bfe116",
   "metadata": {},
   "source": [
    "# SEG-D Reader — Step‑by‑Step\n",
    "\n",
    "This notebook walks you **from a raw SEG‑D file to first visualizations**, without relying on a dedicated SEG‑D Python package.\n",
    "It includes:\n",
    "- Lightweight binary helpers (BCD, big‑endian reads).\n",
    "- A minimal parser for key headers (General Header 1 + Channel Set Descriptors).\n",
    "- A small `SegDReader` to peek the first record and traces.\n",
    "- Utilities to estimate samples per trace and compute quick stats.\n",
    "- Ready‑to‑use plotting helpers for a first look (image and wiggle).\n",
    "\n",
    "> **Assumptions / limitations**  \n",
    "> This minimal reader targets common airborne/marine field tapes where sample formats are **16‑bit integers (format code 8036)**\n",
    "> or **32‑bit floats (format code 8058)**. Other variants may need tweaks in the parsing logic.\n",
    "> Header layouts in SEG‑D can vary; this notebook focuses on a pragmatic subset for quick QC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533599ce",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- `numpy` and `matplotlib` installed (already imported below).\n",
    "- A **SEG‑D** file on disk (e.g., copied from media or provided by your acquisition team)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e283d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Imports ====\n",
    "# Standard library\n",
    "import os, struct, io, math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display options\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af4096",
   "metadata": {},
   "source": [
    "## 1) Point to your SEG‑D file\n",
    "\n",
    "Update `SEGD_PATH` to the file you want to inspect. The cell validates the path and prints the file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: /Users/kavehdehghan/Downloads/SEGD/1001.1.2.expl.segd  |  Size: 868.13 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# <<< EDIT ME >>>\n",
    "SEGD_PATH = \"Path to Your SEG-D file.segd\"  # or .sgd / .segd — use your actual file path\n",
    "\n",
    "# --- Basic validation ---\n",
    "assert isinstance(SEGD_PATH, str) and len(SEGD_PATH) > 0, \"Please provide a non-empty path string.\"\n",
    "if not os.path.exists(SEGD_PATH):\n",
    "    print(\"⚠️  The file path does not exist yet — edit SEGD_PATH above.\")\n",
    "else:\n",
    "    size_mb = os.path.getsize(SEGD_PATH) / (1024*1024)\n",
    "    print(f\"Found: {SEGD_PATH}  |  Size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a637b02",
   "metadata": {},
   "source": [
    "## 2) Binary helpers\n",
    "\n",
    "These functions decode **BCD** bytes and read **big‑endian** unsigned integers commonly found in SEG‑D headers.\n",
    "Each helper is tiny but keeps the parsing code below clean and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497a283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Small binary helpers\n",
    "# ----------------------------\n",
    "def to_bcd_byte(byte_val: int) -> Optional[int]:\n",
    "    tens = (byte_val >> 4) & 0xF\n",
    "    ones = byte_val & 0xF\n",
    "    if tens > 9 or ones > 9:\n",
    "        return None\n",
    "    return tens * 10 + ones\n",
    "\n",
    "def read_uint16_be(b, off):\n",
    "    return int.from_bytes(b[off:off+2], \"big\")\n",
    "\n",
    "def read_uint24_be(b, off):\n",
    "    return int.from_bytes(b[off:off+3], \"big\")\n",
    "\n",
    "def read_uint32_be(b, off):\n",
    "    return int.from_bytes(b[off:off+4], \"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9a239",
   "metadata": {},
   "source": [
    "## 3) Lightweight data classes\n",
    "\n",
    "We use small `@dataclass` containers for the key header pieces we parse. This keeps the returned objects\n",
    "easy to inspect and debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541a7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Data classes\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class GeneralHeader1:\n",
    "    format_code_bcd: Optional[int]\n",
    "    year_bcd: Optional[int]\n",
    "    julian_day_bcd: Optional[int]\n",
    "    hour_bcd: Optional[int]\n",
    "    minute_bcd: Optional[int]\n",
    "    second_bcd: Optional[int]\n",
    "    additional_gh_blocks: int\n",
    "    channel_sets_per_scan_type_bcd: Optional[int]\n",
    "    extended_header_blocks_count: Optional[int]\n",
    "    external_header_blocks_count: Optional[int]\n",
    "\n",
    "@dataclass\n",
    "class ChannelSetDescriptor:\n",
    "    num_channels: int\n",
    "\n",
    "@dataclass\n",
    "class ParsedSEGDRecord:\n",
    "    gh1: GeneralHeader1\n",
    "    header_size_bytes: int\n",
    "    channel_sets: List[ChannelSetDescriptor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565050c",
   "metadata": {},
   "source": [
    "## 4) Header parsers (General Header 1 & Channel Set Descriptors)\n",
    "\n",
    "The functions below extract a **minimal but useful subset** of fields from:\n",
    "- **General Header 1**: revision, recording system ID, sample interval, format code (via BCD), etc.\n",
    "- **Channel Set Descriptors**: number of channels and basic sampling info.\n",
    "\n",
    "> If your data uses additional header blocks (e.g., Scan Type, Extended Headers), you can extend these parsers similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Parsers\n",
    "# ----------------------------\n",
    "def parse_general_header1(block: bytes) -> GeneralHeader1:\n",
    "    fmt_code = (block[2] >> 4)*1000 + (block[2]&0xF)*100 + (block[3]>>4)*10 + (block[3]&0xF)\n",
    "    year2 = to_bcd_byte(block[10])\n",
    "    julian_hundreds = block[11] & 0xF\n",
    "    julian_tens_ones = to_bcd_byte(block[12])\n",
    "    julian_day = julian_hundreds*100 + (julian_tens_ones or 0) if julian_tens_ones else None\n",
    "    hour = to_bcd_byte(block[13])\n",
    "    minute = to_bcd_byte(block[14])\n",
    "    second = to_bcd_byte(block[15])\n",
    "    addl_gh = (block[11] >> 4) & 0xF\n",
    "    ch_sets = to_bcd_byte(block[28])\n",
    "    ext_hdr = None if block[30] == 0xFF else to_bcd_byte(block[30])\n",
    "    ext_ext = None if block[31] == 0xFF else to_bcd_byte(block[31])\n",
    "    return GeneralHeader1(\n",
    "        format_code_bcd=fmt_code,\n",
    "        year_bcd=year2,\n",
    "        julian_day_bcd=julian_day,\n",
    "        hour_bcd=hour,\n",
    "        minute_bcd=minute,\n",
    "        second_bcd=second,\n",
    "        additional_gh_blocks=addl_gh,\n",
    "        channel_sets_per_scan_type_bcd=ch_sets,\n",
    "        extended_header_blocks_count=ext_hdr,\n",
    "        external_header_blocks_count=ext_ext,\n",
    "    )\n",
    "\n",
    "def parse_channel_set_descriptor(block: bytes) -> ChannelSetDescriptor:\n",
    "    num_channels = read_uint16_be(block, 8)  # bytes 9–10\n",
    "    return ChannelSetDescriptor(num_channels=num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee54dc",
   "metadata": {},
   "source": [
    "## 5) A tiny `SegDReader`\n",
    "\n",
    "`SegDReader` opens the file and parses the **first record**, exposing helpers to:\n",
    "- Inspect header objects\n",
    "- Read the first trace\n",
    "- Estimate samples per trace\n",
    "\n",
    "It is intentionally minimal; for production, you might add buffered reading and full record iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42e228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Reader\n",
    "# ----------------------------\n",
    "class SegDReader:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.data = f.read()\n",
    "\n",
    "    def parse_first_record(self) -> ParsedSEGDRecord:\n",
    "        b = self.data\n",
    "        gh1 = parse_general_header1(b[:32])\n",
    "        gh_blocks_total = 1 + max(gh1.additional_gh_blocks, 0)\n",
    "        offs = gh_blocks_total * 32\n",
    "\n",
    "        # Channel sets\n",
    "        channel_sets = []\n",
    "        csd_count = gh1.channel_sets_per_scan_type_bcd or 0\n",
    "        for i in range(csd_count):\n",
    "            block = b[offs:offs+32]\n",
    "            if len(block) < 32: break\n",
    "            channel_sets.append(parse_channel_set_descriptor(block))\n",
    "            offs += 32\n",
    "\n",
    "        # Skip extended/external headers\n",
    "        offs += (gh1.extended_header_blocks_count or 0) * 32\n",
    "        offs += (gh1.external_header_blocks_count or 0) * 32\n",
    "\n",
    "        return ParsedSEGDRecord(gh1=gh1, header_size_bytes=offs, channel_sets=channel_sets)\n",
    "\n",
    "    def read_first_trace(self, header_size: int, sample_count: int, fmt_code: Optional[int]):\n",
    "        # First 20-byte trace header\n",
    "        th = self.data[header_size:header_size+20]\n",
    "        trc_num = int.from_bytes(th[4:6], \"big\") if len(th) >= 6 else None\n",
    "        data_offset = header_size + 20\n",
    "\n",
    "        if fmt_code == 8058:  # IEEE float (4 bytes/sample)\n",
    "            nbytes = sample_count * 4\n",
    "            raw = self.data[data_offset:data_offset+nbytes]\n",
    "            samples = list(struct.unpack(f\">{sample_count}f\", raw)) if len(raw) == nbytes else []\n",
    "            return trc_num, samples\n",
    "\n",
    "        elif fmt_code == 8036:  # 16-bit signed int (2 bytes/sample)\n",
    "            nbytes = sample_count * 2\n",
    "            raw = self.data[data_offset:data_offset+nbytes]\n",
    "            samples = list(struct.unpack(f\">{sample_count}h\", raw)) if len(raw) == nbytes else []\n",
    "            return trc_num, samples\n",
    "\n",
    "        else:\n",
    "            return trc_num, []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012b680",
   "metadata": {},
   "source": [
    "## 6) Utilities\n",
    "\n",
    "- `estimate_samples_per_trace()` — heuristically guesses samples per trace based on header info and file size.\n",
    "- `count_traces_in_record()` — counts the number of traces in the first record.\n",
    "- `segd_stats()` — quick amplitude stats for sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69fbca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_samples_per_trace(rdr: SegDReader) -> Optional[int]:\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    # GH2 only exists if there are additional GH blocks\n",
    "    if gh1.additional_gh_blocks >= 1 and len(b) >= 64:\n",
    "        gh2_block = b[32:64]\n",
    "        record_length_us = read_uint32_be(gh2_block, 16)   # bytes 17–20\n",
    "        # Try to decode sample interval\n",
    "        sample_interval_code = gh1.sample_interval_code if hasattr(gh1, \"sample_interval_code\") else None\n",
    "        sample_interval_us = None\n",
    "\n",
    "        # Simple lookup for common codes (manufacturer-dependent!)\n",
    "        # This may need adjustment for your data\n",
    "        lookup = {\n",
    "            1: 250,    # 250 µs (4 ms)\n",
    "            2: 500,    # 500 µs (2 ms)\n",
    "            3: 1000,   # 1000 µs (1 ms)\n",
    "            4: 2000,   # 2000 µs (0.5 ms)\n",
    "        }\n",
    "        if sample_interval_code in lookup:\n",
    "            sample_interval_us = lookup[sample_interval_code]\n",
    "\n",
    "        # If GH1 code is invalid, check GH2 bytes 25–27\n",
    "        if sample_interval_us is None:\n",
    "            sample_interval_us = read_uint24_be(gh2_block, 24)  # bytes 25–27\n",
    "\n",
    "        if record_length_us and sample_interval_us:\n",
    "            return int(record_length_us / sample_interval_us)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e39a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_traces_in_record(segd_path: str):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "\n",
    "    total_traces = sum(cs.num_channels for cs in rec.channel_sets)\n",
    "    print(f\"Estimated number of traces in this record: {total_traces}\")\n",
    "    return total_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38b1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segd_stats(segd_path: str, n_traces: int = 50):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "    fmt_code = rec.gh1.format_code_bcd\n",
    "    nsamples = estimate_samples_per_trace(rdr)\n",
    "\n",
    "    # ---- sample interval ----\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    sample_interval_us = None\n",
    "    if hasattr(gh1, \"sample_interval_code\"):\n",
    "        lookup = {1: 250, 2: 500, 3: 1000, 4: 2000}\n",
    "        sample_interval_us = lookup.get(getattr(gh1, \"sample_interval_code\", None))\n",
    "    if sample_interval_us is None and len(b) >= 64:\n",
    "        sample_interval_us = read_uint24_be(b[32:64], 24)\n",
    "    dt = sample_interval_us * 1e-6 if sample_interval_us else 0.001\n",
    "\n",
    "    # ---- read traces ----\n",
    "    traces = read_traces(rdr, rec.header_size_bytes, n_traces, nsamples, fmt_code)\n",
    "    if not traces:\n",
    "        print(\"No traces decoded\")\n",
    "        return\n",
    "\n",
    "    import numpy as np\n",
    "    data = np.array([s for _, s in traces]).T  # shape (samples, traces)\n",
    "\n",
    "    stats = {\n",
    "        \"Format code\": fmt_code,\n",
    "        \"Number of traces read\": data.shape[1],\n",
    "        \"Samples per trace\": data.shape[0],\n",
    "        \"Sample interval (µs)\": sample_interval_us,\n",
    "        \"Sample interval (s)\": dt,\n",
    "        \"Trace length (s)\": data.shape[0] * dt,\n",
    "        \"Amplitude min\": float(np.min(data)),\n",
    "        \"Amplitude max\": float(np.max(data)),\n",
    "        \"Amplitude mean\": float(np.mean(data)),\n",
    "        \"Amplitude std\": float(np.std(data)),\n",
    "        \"Amplitude RMS\": float(np.sqrt(np.mean(data**2))),\n",
    "    }\n",
    "\n",
    "    # print nicely\n",
    "    for k, v in stats.items():\n",
    "        print(f\"{k:25s}: {v}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da25da",
   "metadata": {},
   "source": [
    "## 7) Quick file summary\n",
    "\n",
    "`segd_summary(path)` gives you a compact overview: revision, sample interval, format code, channels, traces/record, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc0e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def segd_summary(segd_path: str):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "    fmt_code = rec.gh1.format_code_bcd\n",
    "    nsamples = estimate_samples_per_trace(rdr)\n",
    "\n",
    "    # ---- sample interval ----\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    sample_interval_us = None\n",
    "    if hasattr(gh1, \"sample_interval_code\"):\n",
    "        lookup = {1: 250, 2: 500, 3: 1000, 4: 2000}\n",
    "        sample_interval_us = lookup.get(getattr(gh1, \"sample_interval_code\", None))\n",
    "    if sample_interval_us is None and len(b) >= 64:\n",
    "        sample_interval_us = read_uint24_be(b[32:64], 24)\n",
    "    dt = sample_interval_us * 1e-6 if sample_interval_us else 0.001\n",
    "\n",
    "    # ---- channel sets → traces per record ----\n",
    "    total_channels = sum(cs.num_channels for cs in rec.channel_sets)\n",
    "\n",
    "    # ---- trace size ----\n",
    "    if fmt_code == 8036:  # 16-bit int\n",
    "        bytes_per_sample = 2\n",
    "    elif fmt_code == 8058:  # 32-bit float\n",
    "        bytes_per_sample = 4\n",
    "    else:\n",
    "        bytes_per_sample = 2  # fallback\n",
    "\n",
    "    bytes_per_trace = nsamples * bytes_per_sample\n",
    "    bytes_per_record = total_channels * bytes_per_trace\n",
    "\n",
    "    # ---- file size ----\n",
    "    file_size = os.path.getsize(segd_path)\n",
    "    est_records = file_size / bytes_per_record if bytes_per_record > 0 else None\n",
    "    est_total_traces = est_records * total_channels if est_records else None\n",
    "\n",
    "    # ---- print summary ----\n",
    "    print(\"=== SEG-D File Summary ===\")\n",
    "    print(f\"File size on disk         : {file_size/1e6:.1f} MB\")\n",
    "    print(f\"Format code               : {fmt_code}\")\n",
    "    print(f\"Channels per record       : {total_channels}\")\n",
    "    print(f\"Samples per trace         : {nsamples}\")\n",
    "    print(f\"Sample interval (µs)      : {sample_interval_us}\")\n",
    "    print(f\"Sample interval (s)       : {dt}\")\n",
    "    print(f\"Trace length (s)          : {nsamples*dt:.2f}\")\n",
    "    print(f\"Bytes per trace           : {bytes_per_trace/1e3:.1f} kB\")\n",
    "    print(f\"Bytes per record (est.)   : {bytes_per_record/1e6:.1f} MB\")\n",
    "    print(f\"Estimated records in file : {est_records:.1f}\")\n",
    "    print(f\"Estimated total traces    : {est_total_traces:.0f}\")\n",
    "\n",
    "    return {\n",
    "        \"file_size_bytes\": file_size,\n",
    "        \"channels_per_record\": total_channels,\n",
    "        \"samples_per_trace\": nsamples,\n",
    "        \"sample_interval_s\": dt,\n",
    "        \"trace_length_s\": nsamples*dt,\n",
    "        \"bytes_per_trace\": bytes_per_trace,\n",
    "        \"bytes_per_record\": bytes_per_record,\n",
    "        \"estimated_records\": est_records,\n",
    "        \"estimated_total_traces\": est_total_traces\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b158d",
   "metadata": {},
   "source": [
    "## 8) First-look plots\n",
    "\n",
    "Two helpers to visualize your data fast:\n",
    "\n",
    "- `plot_image_section()` — an **image** (traces stacked) for a quick section view.\n",
    "- `plot_wiggle_section()` — a classic **wiggle** plot for a subset of traces.\n",
    "\n",
    "> Tip: Start with a small number of traces to confirm parsing works; then scale up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be19b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image_section(segd_path: str, n_traces: int = 50, downsample: int = 4, clip: float = 0.2):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "    fmt_code = rec.gh1.format_code_bcd\n",
    "    nsamples = estimate_samples_per_trace(rdr)\n",
    "\n",
    "    # ---- sample interval (µs) ----\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    sample_interval_us = None\n",
    "    if hasattr(gh1, \"sample_interval_code\"):\n",
    "        lookup = {1: 250, 2: 500, 3: 1000, 4: 2000}\n",
    "        sample_interval_us = lookup.get(getattr(gh1, \"sample_interval_code\", None))\n",
    "    if sample_interval_us is None and len(b) >= 64:\n",
    "        sample_interval_us = read_uint24_be(b[32:64], 24)\n",
    "    dt = sample_interval_us * 1e-6 if sample_interval_us else 0.001\n",
    "\n",
    "    # ---- read traces ----\n",
    "    traces = read_traces(rdr, rec.header_size_bytes, n_traces, nsamples, fmt_code)\n",
    "    if not traces:\n",
    "        print(\"No traces decoded\")\n",
    "        return\n",
    "\n",
    "    import numpy as np\n",
    "    data = np.array([s for _, s in traces]).T  # [samples, traces]\n",
    "    if downsample > 1:\n",
    "        data = data[::downsample, :]\n",
    "\n",
    "    # normalize per trace\n",
    "    max_per_trace = np.max(np.abs(data), axis=0, keepdims=True)\n",
    "    max_per_trace[max_per_trace == 0] = 1\n",
    "    data = data / max_per_trace\n",
    "\n",
    "    # apply clipping (optional)\n",
    "    data = np.clip(data, -clip, clip)\n",
    "\n",
    "    # time axis\n",
    "    nt, nx = data.shape\n",
    "    times = np.arange(nt) * downsample * dt\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    extent = [0, nx, times[-1], times[0]]\n",
    "    plt.imshow(\n",
    "        data,\n",
    "        cmap=\"gray\",\n",
    "        aspect=\"auto\",\n",
    "        interpolation=\"bilinear\",  # smoother\n",
    "        extent=extent,\n",
    "        vmin=-clip,\n",
    "        vmax=clip\n",
    "    )\n",
    "    plt.title(f\"Seismic Section — First {n_traces} Traces (Format {fmt_code})\")\n",
    "    plt.xlabel(\"Trace index\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.colorbar(label=\"Normalized amplitude (clipped)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59117347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def read_traces(rdr, header_size_bytes, n_traces, nsamples, fmt_code):\n",
    "    \"\"\"\n",
    "    Read the first `n_traces` traces from the SEG-D file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rdr : SegDReader\n",
    "        The reader object with .data (raw file bytes).\n",
    "    header_size_bytes : int\n",
    "        Offset to the first trace (from parse_first_record()).\n",
    "    n_traces : int\n",
    "        How many traces to read.\n",
    "    nsamples : int\n",
    "        Number of samples per trace (estimated from headers).\n",
    "    fmt_code : int\n",
    "        SEG-D format code (e.g., 8036=int16, 8058=float32).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of (trace_index, np.ndarray)\n",
    "        Each entry is (trace number, samples).\n",
    "    \"\"\"\n",
    "    traces = []\n",
    "    b = rdr.data\n",
    "    offs = header_size_bytes\n",
    "\n",
    "    if nsamples is None:\n",
    "        print(\"⚠️ Cannot read traces: unknown number of samples.\")\n",
    "        return []\n",
    "\n",
    "    # Choose decoding rule based on format code\n",
    "    if fmt_code == 8036:   # 16-bit int\n",
    "        bytes_per_sample = 2\n",
    "        fmt = \">h\"   # big-endian int16\n",
    "    elif fmt_code == 8058: # 32-bit float\n",
    "        bytes_per_sample = 4\n",
    "        fmt = \">f\"   # big-endian float32\n",
    "    else:\n",
    "        print(f\"⚠️ Unknown format code {fmt_code}, assuming int16\")\n",
    "        bytes_per_sample = 2\n",
    "        fmt = \">h\"\n",
    "\n",
    "    bytes_per_trace = nsamples * bytes_per_sample\n",
    "\n",
    "    for i in range(n_traces):\n",
    "        trc_offs = offs + i * (20 + bytes_per_trace)  # 20-byte trace header\n",
    "        if trc_offs + 20 + bytes_per_trace > len(b):\n",
    "            break\n",
    "        # skip 20-byte trace header\n",
    "        dbytes = b[trc_offs+20 : trc_offs+20+bytes_per_trace]\n",
    "\n",
    "        # unpack samples\n",
    "        samples = [\n",
    "            struct.unpack(fmt, dbytes[j:j+bytes_per_sample])[0]\n",
    "            for j in range(0, len(dbytes), bytes_per_sample)\n",
    "        ]\n",
    "        traces.append((i, np.array(samples, dtype=float)))\n",
    "\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wiggle_section(segd_path: str, n_traces: int = 20, downsample: int = 10):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "    fmt_code = rec.gh1.format_code_bcd\n",
    "    nsamples = estimate_samples_per_trace(rdr)\n",
    "\n",
    "    # ---- Try to extract sample interval (µs) ----\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    sample_interval_us = None\n",
    "    if hasattr(gh1, \"sample_interval_code\"):\n",
    "        # simple lookup — may need refinement for your acquisition system\n",
    "        lookup = {\n",
    "            1: 250,    # 0.25 ms\n",
    "            2: 500,    # 0.5 ms\n",
    "            3: 1000,   # 1 ms\n",
    "            4: 2000,   # 2 ms\n",
    "        }\n",
    "        sample_interval_us = lookup.get(gh1.sample_interval_code)\n",
    "    if sample_interval_us is None and len(b) >= 64:\n",
    "        sample_interval_us = read_uint24_be(b[32:64], 24)  # GH2 bytes 25–27\n",
    "\n",
    "    dt = sample_interval_us * 1e-6 if sample_interval_us else 0.001  # fallback 1 ms\n",
    "\n",
    "    traces = read_traces(rdr, rec.header_size_bytes, n_traces, nsamples, fmt_code)\n",
    "    if not traces:\n",
    "        print(\"No traces decoded\")\n",
    "        return\n",
    "\n",
    "    import numpy as np\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i, (trc_num, s) in enumerate(traces):\n",
    "        s = np.array(s)[::downsample]  # downsample for speed/clarity\n",
    "        t = np.arange(len(s)) * downsample * dt  # convert to seconds\n",
    "\n",
    "        # Normalize each trace individually\n",
    "        if np.max(np.abs(s)) > 0:\n",
    "            s = s / np.max(np.abs(s)) * 0.4  # scale to +/-0.4 around center\n",
    "\n",
    "        x = i + s\n",
    "        plt.plot(x, t, 'k', lw=0.5)\n",
    "        plt.fill_betweenx(t, i, x, where=(s > 0), color='black', alpha=0.6)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Wiggle Plot — First {n_traces} traces (Format {fmt_code})\")\n",
    "    plt.xlabel(\"Trace index\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_wiggle_section(SEGD_PATH, n_traces=10, downsample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b2c7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_section_real_amp(\n",
    "    segd_path: str,\n",
    "    n_traces: int = 50,\n",
    "    downsample: int = 4,\n",
    "    clip: Optional[float] = None,\n",
    "    tmin: float = 0.0,\n",
    "    tmax: Optional[float] = None\n",
    "):\n",
    "    rdr = SegDReader(segd_path)\n",
    "    rec = rdr.parse_first_record()\n",
    "    fmt_code = rec.gh1.format_code_bcd\n",
    "    nsamples = estimate_samples_per_trace(rdr)\n",
    "\n",
    "    # ---- sample interval ----\n",
    "    b = rdr.data\n",
    "    gh1 = parse_general_header1(b[:32])\n",
    "    sample_interval_us = None\n",
    "    if hasattr(gh1, \"sample_interval_code\"):\n",
    "        lookup = {1: 250, 2: 500, 3: 1000, 4: 2000}\n",
    "        sample_interval_us = lookup.get(getattr(gh1, \"sample_interval_code\", None))\n",
    "    if sample_interval_us is None and len(b) >= 64:\n",
    "        sample_interval_us = read_uint24_be(b[32:64], 24)\n",
    "    dt = sample_interval_us * 1e-6 if sample_interval_us else 0.001\n",
    "\n",
    "    # ---- read traces ----\n",
    "    traces = read_traces(rdr, rec.header_size_bytes, n_traces, nsamples, fmt_code)\n",
    "    if not traces:\n",
    "        print(\"No traces decoded\")\n",
    "        return\n",
    "\n",
    "    import numpy as np\n",
    "    data = np.array([s for _, s in traces]).T\n",
    "    if downsample > 1:\n",
    "        data = data[::downsample, :]\n",
    "\n",
    "    # ---- build time axis ----\n",
    "    nt, nx = data.shape\n",
    "    times = np.arange(nt) * downsample * dt\n",
    "\n",
    "    # ---- select time window ----\n",
    "    if tmax is None:\n",
    "        tmax = times[-1]\n",
    "    mask = (times >= tmin) & (times <= tmax)\n",
    "    data = data[mask, :]\n",
    "    times = times[mask]\n",
    "\n",
    "    # ---- clipping ----\n",
    "    if clip is None:\n",
    "        limit = np.percentile(np.abs(data), 98)\n",
    "    else:\n",
    "        limit = clip\n",
    "\n",
    "    # ---- plot ----\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    extent = [0, nx, times[-1], times[0]]\n",
    "    plt.imshow(\n",
    "        data,\n",
    "        cmap=\"gray\",\n",
    "        aspect=\"auto\",\n",
    "        interpolation=\"bilinear\",\n",
    "        extent=extent,\n",
    "        vmin=-limit,\n",
    "        vmax=limit\n",
    "    )\n",
    "    plt.title(f\"Seismic Section — First {n_traces} traces (Format {fmt_code})\")\n",
    "    plt.xlabel(\"Trace index\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.colorbar(label=\"Amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cc43a",
   "metadata": {},
   "source": [
    "## 9) Example: Summarize and plot\n",
    "\n",
    "Run the cells below after setting `SEGD_PATH` to your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Summary ---\n",
    "if os.path.exists(SEGD_PATH):\n",
    "    summary = segd_summary(SEGD_PATH)\n",
    "else:\n",
    "    summary = None\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- First-look image section ---\n",
    "# Tweak n_traces / downsample / clip as needed for performance/visibility.\n",
    "if os.path.exists(SEGD_PATH):\n",
    "    plot_image_section(SEGD_PATH, n_traces=64, downsample=2, clip=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7605e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional: Wiggle plot for first N traces ---\n",
    "if os.path.exists(SEGD_PATH):\n",
    "    plot_wiggle_section(SEGD_PATH, n_traces=24, downsample=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d9ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notes & next steps\n",
    "\n",
    "- If you hit an unknown **format code**, add a `elif` branch where samples are unpacked (see comments in the reader).\n",
    "- For **batch processing** or conversion (e.g., to SEG‑Y), consider wrapping the record/trace iteration with writers\n",
    "  from libraries like `segyio` (for SEG‑Y) once you extract trace arrays here.\n",
    "- If your dataset uses **extended headers** or specialized **demultiplexed layouts**, extend the header parsers accordingly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
